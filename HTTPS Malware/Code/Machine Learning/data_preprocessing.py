import pandas as pd
import numpy as np
import math
from sklearn.model_selection import train_test_split
import os
from pathlib import Path
from sklearn import preprocessing
import joblib

def normalize_dataset(df,file):
    i=0
    for col in df.columns:
        if col not in ['4-tuple', 'dataset','label']:
            df[col] = df[col].astype('float64')
            i+=1
            max=0
            for ro in range(df.shape[0]):
                if max<df[col].values[ro]:
                    max=df[col].values[ro]
            if max != 0:
                for ro in range(df.shape[0]):
                    if df[col].values[ro]!=-1:
                        df[col].values[ro]=np.float64(df[col].values[ro]/max)
    df.to_csv(file, index=False, index_label=False)

def split_dataset(root_folder):
    folder=os.path.join(root_folder,'dataset_update_normal_scenario2')
    dataset=pd.read_csv(os.path.join(folder,'extract_dataset.csv'))
    data=dataset.iloc[:,:-1]
    label=dataset.iloc[:,-1]
    X_train, X_test, y_train, y_test = train_test_split( data, label, test_size=0.3, random_state=42, stratify=label)
    # X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)
    train=pd.concat([X_train, y_train], axis=1, join='inner')
    test=pd.concat([X_test, y_test], axis=1, join='inner')
    # vali=pd.concat([X_val, y_val], axis=1, join='inner')
    train=pd.DataFrame(train)
    test=pd.DataFrame(test)
    # vali=pd.DataFrame(vali)
    normalizer = preprocessing.MaxAbsScaler()
    train.iloc[:,2:-1] = normalizer.fit_transform(train.iloc[:,2:-1])
    for column in train.iloc[:,2:-1].columns.values:
        train.loc[train[column] <0, column] = -1
    scaler_filename = os.path.join(root_folder,'Machine Learning',"scaler2.save")
    joblib.dump(normalizer, scaler_filename) 
    # vali.iloc[:,2:-1] = normalizer.transform(vali.iloc[:,2:-1])
    test.iloc[:,2:-1] = normalizer.transform(test.iloc[:,2:-1])
    for column in test.iloc[:,2:-1].columns.values:
        test.loc[test[column] <0, column] = -1
    # for column in vali.iloc[:,2:-1].columns.values:
    #     vali.loc[vali[column] <0, column] = -1
    train.to_csv(os.path.join(folder,'trainSet.csv'), index=False, index_label=False)
    # vali.to_csv(os.path.join(folder,'valiSet.csv'), index=False, index_label=False)
    test.to_csv(os.path.join(folder,'valSet.csv'), index=False, index_label=False)
   
folder=Path(__file__).parents[1]
# split_dataset(folder)
test=pd.read_csv(os.path.join(folder,'dataset_update_normal_scenario2','testset_no_normalize.csv'))
normalizer = joblib.load(os.path.join(folder,'Machine Learning',"scaler2.save"))
test.iloc[:,2:-1] = normalizer.transform(test.iloc[:,2:-1])
for column in test.iloc[:,2:-1].columns.values:
    test.loc[test[column] <0, column] = -1
test.to_csv(os.path.join(folder,'testSet.csv'), index=False, index_label=False)
    # for column in vali.iloc[:,2:-1].columns.values:
    #     vali.loc[vali[column] <0, column] = -1
